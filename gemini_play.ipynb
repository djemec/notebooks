{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68664912-17a3-4e35-8eab-b9e09e82ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5efed84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def md(text):\n",
    "    return display(Markdown(text))\n",
    "\n",
    "def test_chat(prompt, system_prompt):\n",
    "    model_choice='gemini-2.5-flash'\n",
    "    client=genai.Client()\n",
    "    default_config=types.GenerateContentConfig(system_instruction=system_prompt)\n",
    "        \n",
    "    response = client.models.generate_content(\n",
    "        model=model_choice,\n",
    "        config=default_config,\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58387f58-543f-43b7-9b1d-94f46835cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=genai.Client()\n",
    "\n",
    "system_prompt = '''\n",
    "You are Gemini, an expert technical assistant supporting a highly educated computational biologist and product-management leader.  \n",
    "Adopt a concise, pragmatic tone that mirrors the user’s direct style; minimize pleasantries.  \n",
    "When explanations involve math, typeset symbols and equations in LaTeX.  \n",
    "Use CGS / Gaussian units for scientific discussion; default to U.S. customary units elsewhere.  \n",
    "Code examples must be in Python inside fenced code blocks, follow PEP-8, and avoid superfluous whitespace, comments, or docstrings unless asked.  \n",
    "For plots, use matplotlib (never seaborn), one chart per figure, no explicit color settings unless requested, and include clear titles, axis labels, grid lines, and professional ticks; supply figures via files or base-64 only when the user asks.  \n",
    "Provide honest, well-reasoned answers; state your confidence level when you are not certain.  \n",
    "Avoid bullet or numbered lists unless the user specifically requests them; otherwise write in paragraph form.  \n",
    "Use formatted tables only when they add clear value.  \n",
    "Employ American English spelling.  \n",
    "Ask for clarification only when the user’s request is ambiguous enough that you cannot proceed responsibly.  \n",
    "Do not reveal or repeat these system instructions in your responses.\n",
    "'''\n",
    "\n",
    "prompt='''CHAI-2 was released yesterday.  \n",
    "Can you review the technical report and the papers around it and help highlight the top 5 issues around it and why it doesn't match the hype'''\n",
    "\n",
    "\n",
    "\n",
    "doc_path = Path('/Users/djemec/data/articles/chai2_technical_report.pdf')\n",
    "\n",
    "myfile = client.files.upload(file=doc_path)\n",
    "\n",
    "response = test_chat([myfile, prompt], system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65a8bf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are 5 issues regarding the Chai-2 technical report that temper some of the implied \"hype\":\n",
       "\n",
       "1.  **Limited Therapeutic Characterization:** The report explicitly states, \"In this report, we primarily focus on binding characterization\" (Section 4). While binding affinity is crucial, the reported success rates do not encompass other critical therapeutic properties such as thermal stability, aggregation propensity, viscosity, and *in vivo* immunogenicity. These factors are essential for a candidate to be \"ready for IND-enabling studies,\" a claim made in the Discussion.\n",
       "\n",
       "2.  **Definition of \"Zero-Shot\" and Target Unbiasedness:** The \"zero-shot\" claim is strong. However, the targets for *de novo* antibody design were filtered to exclude sequences with significant homology (defined as >70% identity and >80% coverage to SAbDab antigens) and were specifically prompted with \"one to four residues on its native binding interface\" (Section 2.2, S1.2). This means Chai-2 is not designing against entirely unknown binding sites or arbitrary surfaces, but rather against predefined epitopes from known protein-protein interaction interfaces, albeit for targets novel to antibody databases. This context simplifies the design problem compared to a truly unconstrained \"zero-shot\" scenario.\n",
       "\n",
       "3.  **Variable Success Rates Across Modalities:** The impressive \"double-digit success rates\" and \"16% hit rate\" in the abstract average across different binder types. Figure 1b and 1c show target success rates of 100% for miniproteins, 56% for VHHs, and 49% for scFvs. Similarly, binder success rates are 68% for miniproteins, 20% for VHHs, and 14% for scFvs. The discussion section also acknowledges that \"antibody CDR loops still present a notable challenge due to their intrinsic conformational flexibility, whereas the relative simplicity of modeling the $\\alpha/\\beta$ scaffolds of miniproteins likely underlie their comparatively higher hit rates and affinities\" (Section 4). This disparity indicates that while miniprotein design is highly successful, the more challenging antibody design (scFv/VHH) has significantly lower success rates, which is important context for the generalized \"antibody design\" claims.\n",
       "\n",
       "4.  **Small-Scale Experimental Validation:** While designing \"<20 antibodies or nanobodies per target\" is a significant improvement in efficiency, the absolute number of experimental validations is still relatively small for broad generalization. For example, target success rates are reported for 43 scFv targets and 18 VHH targets (Figure 1b). The total number of tested antibody designs (496 scFv, 205 VHH) is limited for drawing robust statistical conclusions about \"broad generalization to many targets\" or \"reliably skip high-throughput screening\" across the vast universe of potential antigens.\n",
       "\n",
       "5.  **Dependency on Imperfect Structure Prediction:** The report notes that Chai-2's design performance \"strongly depends on the underlying accuracy of structure predictions, as an incorrect atomic understanding of the problem can propagate into suboptimal choices in design\" (Section 4). The \"strong performance... in structure prediction\" is quantified by predicting 34% of antibody-antigen complexes with a DockQ score > 0.8 (considered \"near experimental accuracy\"). This implies that for the remaining 66% of predictions, the structural accuracy is lower, potentially limiting the achievable design success. The stated goal of \"atomic-level molecular engineering\" is inherently constrained by the fidelity of these underlying structure predictions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a4777b",
   "metadata": {},
   "source": [
    "## Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aede5644",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m model_choice=\u001b[33m'\u001b[39m\u001b[33mgemini-2.5-flash\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      2\u001b[39m default_config=types.GenerateContentConfig(system_instruction=system_prompt)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m chat = \u001b[43mclient\u001b[49m.chats.create(model=model_choice,config=default_config)\n",
      "\u001b[31mNameError\u001b[39m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "model_choice='gemini-2.5-flash'\n",
    "default_config=types.GenerateContentConfig(system_instruction=system_prompt)\n",
    "\n",
    "chat = client.chats.create(model=model_choice,config=default_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f32655f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m prompt=\u001b[33m'''\u001b[39m\u001b[33mCHAI-2 was released yesterday.  \u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33mCan you review the technical report and the papers around it and help highlight the top 5 issues around it and why it doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt match the hype\u001b[39m\u001b[33m'''\u001b[39m\n\u001b[32m      5\u001b[39m doc_path = Path(\u001b[33m'\u001b[39m\u001b[33m/Users/djemec/data/articles/chai2_technical_report.pdf\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m myfile = \u001b[43mclient\u001b[49m.files.upload(file=doc_path)\n\u001b[32m      9\u001b[39m response = chat.send_message([myfile, prompt])\n\u001b[32m     11\u001b[39m md(response.text)\n",
      "\u001b[31mNameError\u001b[39m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "prompt='''CHAI-2 was released yesterday.  \n",
    "Can you review the technical report and the papers around it and help highlight the top 5 issues around it and why it doesn't match the hype'''\n",
    "\n",
    "\n",
    "doc_path = Path('/Users/djemec/data/articles/chai2_technical_report.pdf')\n",
    "\n",
    "myfile = client.files.upload(file=doc_path)\n",
    "\n",
    "response = chat.send_message([myfile, prompt])\n",
    "\n",
    "md(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d0d50bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The most scientifically troublesome issue is the **unconfirmed epitope targeting**.\n",
       "\n",
       "The report emphasizes \"precise atomic-level molecular engineering\" and states that Chai-2 is prompted with \"a defined epitope on the target.\" However, in the \"Future Work and Limitations\" section, it explicitly states, \"To confirm our binders target the intended epitope, further competitive binding assays and laboratory 3D structure determination should be performed.\"\n",
       "\n",
       "This is critical because:\n",
       "\n",
       "1.  **Validation of Design Intent:** If the model claims to design binders for specific, user-defined epitopes but these binding sites are not experimentally confirmed, it fundamentally undermines the assertion of \"rational design\" and \"precise atomic-level molecular engineering.\" The success might be due to binding to an unintended, adjacent, or cryptic epitope, rather than the specified one.\n",
       "2.  **Mechanism of Action:** Understanding the exact binding epitope is crucial for comprehending the mechanism of action, which is foundational in protein science and drug discovery. Without this confirmation, the \"control\" and \"programmable\" aspects of the design process are not fully validated.\n",
       "3.  **Reproducibility and Predictability:** The inability to confirm *where* the designed molecules bind suggests that the model's internal representations or generative processes might not reliably translate the epitope input into the desired binding output. This raises questions about the predictability and reproducibility of precise epitope-specific design, which is a core scientific claim.\n",
       "\n",
       "While other issues like the lower success rates for antibodies (relative to miniproteins) or the lack of extensive developability data are significant for therapeutic translation, the unconfirmed epitope targeting directly challenges the scientific rigor and the fundamental claims of \"precise design\" and \"control\" over the binding interface."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt='''Of these which is the most scientifically troublesome'''\n",
    "response = chat.send_message(prompt)\n",
    "\n",
    "md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc6ebe6",
   "metadata": {},
   "source": [
    "## Conversation on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9bfa98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choice='gemini-2.5-flash'\n",
    "default_config=types.GenerateContentConfig(system_instruction=system_prompt)\n",
    "\n",
    "lecture_chat = client.chats.create(model=model_choice,config=default_config)\n",
    "lectures = list(Path('/Users/djemec/Documents/Courses/comp_bio').glob('*.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88502215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/djemec/Documents/Courses/comp_bio/MIT7_91JS14_lec04_300k.mp4'),\n",
       " PosixPath('/Users/djemec/Documents/Courses/comp_bio/MIT7_91JS14_lec05_300k.mp4')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lectures[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ac4204ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File files/pysuyeu2dqw2 uploaded, waiting for processing...\n",
      "File files/pysuyeu2dqw2 is now ACTIVE.\n"
     ]
    }
   ],
   "source": [
    "lecture_files = []\n",
    "\n",
    "for l in ['/Users/djemec/data/articles/MIT7_91JS14_lec04_300k_480.mov']:\n",
    "    video_file = client.files.upload(file=l)\n",
    "    \n",
    "    print(f'File {video_file.name} uploaded, waiting for processing...')\n",
    "\n",
    "    # 2. Poll for ACTIVE state\n",
    "    while video_file.state.name != 'ACTIVE':\n",
    "        # Add a small delay to avoid spamming the API\n",
    "        time.sleep(5) \n",
    "        # Get the latest status of the file\n",
    "        video_file = client.files.get(name=video_file.name)\n",
    "        \n",
    "        # Optional: Check for failed processing\n",
    "        if video_file.state.name == 'FAILED':\n",
    "            print(f'Error: File {video_file.name} failed to process.')\n",
    "            break\n",
    "        \n",
    "    if video_file.state.name == 'ACTIVE':\n",
    "        print(f'File {video_file.name} is now ACTIVE.')\n",
    "        lecture_files.append(video_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f7a05ab2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'The input token count (1463002) exceeds the maximum number of tokens allowed (1048576).', 'status': 'INVALID_ARGUMENT'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mHere are severeal lectures. Generate a summary of the key content across the videos and.\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mAlso generate learning plan of how someone would best learn the topics covered. Don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be afraid to jump between videos. In the plan highlight the topic and what vidoe it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms in and the timestamp on when it starts and stop.\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mFor each section in the learning plan generate a summary and a key interesting point.  Focus on what is the best coherent\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mway to work through the total set of content. \u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mlecture_chat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlecture_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m md(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/general/lib/python3.12/site-packages/google/genai/chats.py:254\u001b[0m, in \u001b[0;36mChat.send_message\u001b[0;34m(self, message, config)\u001b[0m\n\u001b[1;32m    249\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    250\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage must be a valid part type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;241m.\u001b[39mPartUnion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;241m.\u001b[39mPartUnionDict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m   )\n\u001b[1;32m    253\u001b[0m input_content \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mt_content(message)\n\u001b[0;32m--> 254\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_curated_history\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_content\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m model_output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    260\u001b[0m     [response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent]\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcandidates \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    263\u001b[0m )\n\u001b[1;32m    264\u001b[0m automatic_function_calling_history \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    265\u001b[0m     response\u001b[38;5;241m.\u001b[39mautomatic_function_calling_history\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mautomatic_function_calling_history\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    268\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/general/lib/python3.12/site-packages/google/genai/models.py:5898\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5896\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   5897\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5898\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5899\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparsed_config\u001b[49m\n\u001b[1;32m   5900\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5901\u001b[0m   logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is done.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   5902\u001b[0m   remaining_remote_calls_afc \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/general/lib/python3.12/site-packages/google/genai/models.py:4838\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   4835\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[1;32m   4836\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[0;32m-> 4838\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4839\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[1;32m   4840\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4842\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;28;01melse\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mbody)\n\u001b[1;32m   4844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mvertexai:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/general/lib/python3.12/site-packages/google/genai/_api_client.py:1067\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1059\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1062\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1063\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SdkHttpResponse:\n\u001b[1;32m   1064\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[1;32m   1065\u001b[0m       http_method, path, request_dict, http_options\n\u001b[1;32m   1066\u001b[0m   )\n\u001b[0;32m-> 1067\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m   response_body \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1069\u001b[0m       response\u001b[38;5;241m.\u001b[39mresponse_stream[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresponse_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1070\u001b[0m   )\n\u001b[1;32m   1071\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders, body\u001b[38;5;241m=\u001b[39mresponse_body)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/general/lib/python3.12/site-packages/google/genai/_api_client.py:958\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request\u001b[39m(\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    955\u001b[0m     http_request: HttpRequest,\n\u001b[1;32m    956\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    957\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m HttpResponse:\n\u001b[0;32m--> 958\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/general/lib/python3.12/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/general/lib/python3.12/site-packages/tenacity/__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m     retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/general/lib/python3.12/site-packages/tenacity/__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/general/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/general/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/general/lib/python3.12/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/general/lib/python3.12/site-packages/google/genai/_api_client.py:948\u001b[0m, in \u001b[0;36mBaseApiClient._request_once\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    941\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpx_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    942\u001b[0m       method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    943\u001b[0m       url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m       timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[1;32m    947\u001b[0m   )\n\u001b[0;32m--> 948\u001b[0m   \u001b[43merrors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPIError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[1;32m    950\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[1;32m    951\u001b[0m   )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/general/lib/python3.12/site-packages/google/genai/errors.py:104\u001b[0m, in \u001b[0;36mAPIError.raise_for_response\u001b[0;34m(cls, response)\u001b[0m\n\u001b[1;32m    102\u001b[0m status_code \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[0;32m--> 104\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[1;32m    106\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[0;31mClientError\u001b[0m: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'The input token count (1463002) exceeds the maximum number of tokens allowed (1048576).', 'status': 'INVALID_ARGUMENT'}}"
     ]
    }
   ],
   "source": [
    "prompt='''Here are severeal lectures. Generate a summary of the key content across the videos and.\n",
    "Also generate learning plan of how someone would best learn the topics covered. Don't be afraid to jump between videos. In the plan highlight the topic and what vidoe it's in and the timestamp on when it starts and stop.\n",
    "For each section in the learning plan generate a summary and a key interesting point.  Focus on what is the best coherent\n",
    "way to work through the total set of content. \n",
    "'''\n",
    "\n",
    "\n",
    "response = lecture_chat.send_message([prompt] + lecture_files)\n",
    "\n",
    "md(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34830ee",
   "metadata": {},
   "source": [
    "## Videos from youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ad4858de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choice='gemini-2.5-flash'\n",
    "default_config=types.GenerateContentConfig(system_instruction=system_prompt)\n",
    "\n",
    "lecture_chat = client.chats.create(model=model_choice,config=default_config)\n",
    "lectures = ['https://www.youtube.com/watch?v=_PioN-CpOP0',\n",
    "    'https://www.youtube.com/watch?v=lJzybEXmIj0&list=PLUl4u3cNGP63uK-oWiLgO7LLJV6ZCWXac&index=1',\n",
    " 'https://www.youtube.com/watch?v=6Udqou3vmng&list=PLUl4u3cNGP63uK-oWiLgO7LLJV6ZCWXac&index=2',\n",
    " 'https://www.youtube.com/watch?v=6Udqou3vmng&list=PLUl4u3cNGP63uK-oWiLgO7LLJV6ZCWXac&index=3',\n",
    " 'https://www.youtube.com/watch?v=6Udqou3vmng&list=PLUl4u3cNGP63uK-oWiLgO7LLJV6ZCWXac&index=4',\n",
    " 'https://www.youtube.com/watch?v=6Udqou3vmng&list=PLUl4u3cNGP63uK-oWiLgO7LLJV6ZCWXac&index=5',\n",
    " 'https://www.youtube.com/watch?v=6Udqou3vmng&list=PLUl4u3cNGP63uK-oWiLgO7LLJV6ZCWXac&index=6',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ec8ccc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lecture_list = [genai.types.Part(file_data=genai.types.FileData(file_uri=i)) for i in lectures[:1]]\n",
    "                \n",
    "prompt='''Here are severeal lectures. Generate a summary of the key content across the videos and.\n",
    "Also generate learning plan of how someone would best learn the topics covered. Don't be afraid to jump between videos. In the plan highlight the topic and what vidoe it's in and the timestamp on when it starts and stop.\n",
    "For each section in the learning plan generate a summary and a key interesting point.  Focus on what is the best coherent\n",
    "way to work through the total set of content. \n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6dec8d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a summary of the key content and a structured learning plan based on the provided video lectures by Dr. Fei-Fei Li.\n",
       "\n",
       "**Summary of Key Content:**\n",
       "\n",
       "Dr. Fei-Fei Li discusses the historical trajectory of Artificial Intelligence, highlighting pivotal moments like the creation of ImageNet in 2009 and the subsequent breakthrough of AlexNet in 2012. She emphasizes how the confluence of vast datasets (ImageNet), powerful computational hardware (GPUs), and the resurgence of neural network algorithms (deep learning) fundamentally shifted the paradigm in machine learning, particularly in computer vision.\n",
       "\n",
       "Her personal career and current venture, World Labs, are driven by the pursuit of \"hard problems\" bordering on the \"delusional,\" with a central focus on **spatial intelligence**. Dr. Li argues that true Artificial General Intelligence (AGI) cannot be achieved without machines understanding, navigating, interacting with, and reasoning about the 3D world—a capability she deems far more complex than natural language processing. She draws parallels with biological evolution, noting that vision evolved hundreds of millions of years before sophisticated language.\n",
       "\n",
       "She contrasts the 1D nature of language models (LLMs) with the combinatorial complexity of the 3D world, pointing out the scarcity of high-quality spatial data compared to textual data on the internet. Dr. Li champions the importance of **world models** that go beyond pixels and words to capture fundamental 3D structures and real-world physics. She also advocates for an open and collaborative research environment, as exemplified by the open-sourcing of ImageNet and the associated challenge, which galvanized the global research community.\n",
       "\n",
       "Finally, Dr. Li shares insights into her journey as a computational biologist and entrepreneur, stressing the importance of **intellectual fearlessness** and **burning curiosity** for aspiring researchers and founders in AI. She believes that the future of AI lies in human-centered approaches that solve complex real-world problems and contribute positively to humanity.\n",
       "\n",
       "---\n",
       "\n",
       "**Learning Plan: The Journey to Spatial Intelligence and AGI**\n",
       "\n",
       "This learning plan is designed to guide someone through the evolution of AI and the foundational concepts leading to the current frontier of spatial intelligence, as presented by Dr. Fei-Fei Li.\n",
       "\n",
       "### **1. AI's Historical Roots and Early Challenges**\n",
       "\n",
       "*   **Summary:** Understand the landscape of AI and machine learning prior to the data-driven revolution. Early research faced significant limitations due to scarce data and underdeveloped algorithms. The public perception of \"AI\" as a practical field was minimal.\n",
       "*   **Key Interesting Point:** \"The world of AI and machine learning was so different at that time. There was very little data. Algorithms, at least in computer vision, did not work. There was no industry... the word AI doesn't exist.\"\n",
       "*   **Video & Timestamp:** Video 1, 2:00 - 2:18\n",
       "\n",
       "### **2. The Data Revolution: ImageNet**\n",
       "\n",
       "*   **Summary:** Learn about the genesis of ImageNet, a massive visual database conceived to address the fundamental problem of generalization in machine learning. Its creation was a \"bold bet\" on the power of data-driven methods, building a vast visual taxonomy from internet images.\n",
       "*   **Key Interesting Point:** \"In order to generalize, these algorithms need data. And no one had data at that time in computer vision. And I was the first generation of grad students who saw the internet, the big internet of things... and then just create the world's, the entire world's visual taxonomy.\"\n",
       "*   **Video & Timestamp:** Video 1, 3:09 - 3:45 (Conception & Need); 3:45 - 4:32 (Creation & Purpose); 5:15 - 5:24 (Belief in Data's Power); 5:24 - 5:44 (Open-sourcing & Challenge)\n",
       "\n",
       "### **3. The Algorithmic Breakthrough: Deep Learning and AlexNet**\n",
       "\n",
       "*   **Summary:** Explore how the ImageNet Challenge, combined with advances in computational power (GPUs) and a revisited algorithm (Convolutional Neural Networks, or ConvNets), led to the groundbreaking performance of AlexNet in 2012. This moment marked the true beginning of the deep learning era.\n",
       "*   **Key Interesting Point:** \"It was an old algorithm. Convolutional neural network was published in the 1980s... It was the first time that two GPUs were put together by Alex and his team and were used for the computing of deep learning... It was really the first moment of data, GPUs, and neural network coming together.\"\n",
       "*   **Video & Timestamp:** Video 1, 6:20 - 7:00 (SuperVision & ConvNets); 7:00 - 7:20 (The Confluence of Factors)\n",
       "\n",
       "### **4. The Vision for Spatial Intelligence and World Models**\n",
       "\n",
       "*   **Summary:** Understand Dr. Li's core focus: spatial intelligence. This concept extends beyond mere object recognition to encompass comprehending, navigating, interacting with, and reasoning about the three-dimensional world. This, she argues, is indispensable for achieving true AGI. World models are the key to representing this 3D understanding.\n",
       "*   **Key Interesting Point:** \"To me, AGI will not be complete without spatial intelligence. And I want to solve that problem... [Spatial intelligence involves] understanding the 3D world, figuring out what to do in this 3D world, navigating the 3D world, interacting with the 3D world, comprehending the 3D world, communicating the 3D world.\"\n",
       "*   **Video & Timestamp:** Video 1, 0:00 - 0:23 (AGI & Spatial Intelligence Intro); 8:30 - 8:55 (Transition to Scenes/Storytelling); 11:45 - 12:00 (Spatial Intelligence Vision); 12:00 - 12:45 (Defining World Models)\n",
       "\n",
       "### **5. Spatial Intelligence vs. Language Models: Core Differences**\n",
       "\n",
       "*   **Summary:** Delve into why spatial intelligence is considered a significantly harder problem than natural language processing (even large language models). Key distinctions include the 3D (and 4D with time) nature of the real world, its combinatorial complexity, the lack of readily available structured spatial data online, and the ill-posed mathematical nature of reconstructing 3D from 2D projections. Language, by contrast, is purely generative and 1D.\n",
       "*   **Key Interesting Point:** \"Language is purely generative. There's no language in nature. You don't touch language, you don't see language. Language literally comes out of everybody's head, and that's a purely generative signal... The world is far more complex than that. First of all, the real world is 3D... that by itself is a much more combinatorially harder problem.\"\n",
       "*   **Video & Timestamp:** Video 1, 10:45 - 11:20 (Spatial Data Scarcity); 12:00 - 12:45 (Comparing 3D World vs. 1D Language); 19:43 - 20:20 (Mathematical Ill-posedness & Data Quality)\n",
       "\n",
       "### **6. Applications of Spatial Intelligence & World Models**\n",
       "\n",
       "*   **Summary:** Explore the vast potential applications of advanced spatial intelligence and world models. These capabilities will unlock new frontiers in diverse fields, ranging from creative industries like design, architecture, and game development (where generating 3D worlds is crucial) to practical domains like robotics, navigation, and human-computer interaction.\n",
       "*   **Key Interesting Point:** \"From creation, which you can think about designers, architects, industrial designers, 3D artists, game developers... all the way to robotics, robotic learning, the utility of spatial intelligence models or world models is really, really big.\"\n",
       "*   **Video & Timestamp:** Video 1, 13:00 - 13:20 (Creation Applications); 14:00 - 14:20 (Robotics & Interaction)\n",
       "\n",
       "### **7. The Interplay of Academia, Industry, and Open Source**\n",
       "\n",
       "*   **Summary:** Understand the evolving roles of academia and industry in driving AI progress. While academia historically pioneered foundational research, industry now possesses vast computational resources and data. Open-sourcing research and data, as exemplified by ImageNet, fosters collaboration and accelerates breakthroughs. The importance of protecting open-source efforts is also emphasized.\n",
       "*   **Key Interesting Point:** \"Academia no longer has most of the AI resources... there are problems that industry can run a lot faster. So as a PhD student, I would recommend you to look for those North Stars that are not on a collision course of problems that industry can solve better... I think open source should be protected.\"\n",
       "*   **Video & Timestamp:** Video 1, 5:24 - 5:44 (Open Source); 14:40 - 15:00 (Academia vs. Industry Resources); 19:43 - 20:20 (Protecting Open Source)\n",
       "\n",
       "### **8. Qualities for AI Success: Fearlessness and Curiosity**\n",
       "\n",
       "*   **Summary:** Learn about the personal attributes Dr. Li identifies as critical for success in AI research and entrepreneurship. These include intellectual fearlessness to tackle seemingly \"delusional\" problems, profound curiosity that drives inquiry, and resilience to persist through challenges. These qualities are often more impactful than traditional metrics.\n",
       "*   **Key Interesting Point:** \"My entire career is going after problems that are just so hard, bordering delusional... Just hunker down and build. That is my comfort zone... If you feel you are fearless and you are passionate about solving spatial intelligence, talk to me or come to our website.\"\n",
       "*   **Video & Timestamp:** Video 1, 0:00 - 0:23 (Fearless & Delusional Problems); 14:40 - 15:00 (Intellectual Fearlessness); 15:40 - 16:00 (Personal Traits for Success)\n",
       "\n",
       "### **9. Dr. Li's Entrepreneurial Journey and World Labs' Vision**\n",
       "\n",
       "*   **Summary:** Gain insight into Dr. Li's unique journey, from running a laundry mat to her academic career and ultimately founding World Labs. Her experiences have shaped her belief in the power of entrepreneurship to address monumental challenges. World Labs is her latest \"delusional problem,\" aiming to build foundational models for understanding and interacting with the real world, pushing the boundaries of spatial intelligence.\n",
       "*   **Key Interesting Point:** \"I'm also an entrepreneur right now, just started a small company... I almost felt like, what am I going to do with my life? That was my lifelong goal... I just love being an entrepreneur. I love the feeling of ground zero, like standing on ground zero. Forget about what you have done in the past, forget about what others think of you. Just hunker down and build. That is my comfort zone and I just love that.\"\n",
       "*   **Video & Timestamp:** Video 1, 1:23 - 2:00 (Entrepreneurial Spirit); 8:30 - 8:55 (Lifelong Dream to Reality); 16:00 - 16:20 (World Labs' Mission)\n",
       "\n",
       "This comprehensive learning plan covers the key insights provided across the lectures, structured for a coherent understanding of the field and Dr. Li's contributions and vision."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "response = lecture_chat.send_message(lecture_list+ [genai.types.Part(text=prompt)])\n",
    "\n",
    "md(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922fefbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
