{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b9eae6-e5e7-4d57-8f89-d83d77aa91bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff856719-149e-4976-aebf-9e4e38979bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "from pathlib import Path\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83823c2-8f2f-4e04-983e-79822e1a224a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 31 01:26:49 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   39C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f94cae7e-b668-4a79-8bb8-5468986672a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "shake_data = Path('/home/ubuntu/data/input.txt')\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    device = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(1337)\n",
    "        device = 'cuda'\n",
    "    # elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    #     device = 'mps'\n",
    "    print(f'using {device}')\n",
    "    return device\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32912c63-ab50-48a4-8a3c-bf57cb67fdae",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d55293c-13e7-473f-bab8-81a175d9c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # ensures that you can split embeddings across the heads\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projection for all heads in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        # acts as a triangle mask to prevent seeing the future, called bias for historic reasons\n",
    "        self.register_buffer('bias', torch.tril(torch.ones(config.block_size, \n",
    "                                                           config.block_size)\n",
    "                                               ).view(1,1, config.block_size,config.block_size)\n",
    "                            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, n_embd embedding dimensionality \n",
    "        # calculate query, key, value for all heads in batch, then move head forward\n",
    "        # nh - num heads, hs - head size, C  nh*hs aka channels\n",
    "        qkv = self.c_attn(x)\n",
    "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        # attention (materializes the large (T,T) matrix for all the queries and keys)\n",
    "        # att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        # att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
    "        # att = F.softmax(att, dim=-1)\n",
    "        # y = att @ v # (B, nh, T, T) X (B, nh, T, hs) - > (B, nh, T, hs)\n",
    "        # replace attention with flash attention \n",
    "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True) # flash attention\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "        # output projection\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
    "        self.gelu = nn.GELU(approximate='tanh')\n",
    "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # allows for pathway to pass through gradients instead of going through each \"box\"\n",
    "        # this is a feed forward network\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024 # max sequence length/context\n",
    "    vocab_size: int = 50257 # num of tokens, 50k merges, 256 bytes, 1 EOT\n",
    "    n_layer: int = 12 \n",
    "    n_head: int = 12\n",
    "    n_embd: int = 768\n",
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd), # weight tokenizer element\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd), # weight position element\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]), # hidden layers aka Transformers\n",
    "            ln_f = nn.LayerNorm(config.n_embd), #log normalization \n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias = False) # language model head going from embeddings to vocab\n",
    "\n",
    "        # weight sharing scheme\n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "\n",
    "        # init params\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        std = 0.02\n",
    "        mean = 0.0\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if hasattr(module, 'NANOGPT_SCALE_INIT'):\n",
    "                std *= (2 * self.config.n_layer) ** -0.5\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=mean, std=std)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx is shape (B, T)\n",
    "        B, T = idx.size()\n",
    "        assert T <= self.config.block_size, f'Cannot forward sequence, out of context'\n",
    "        # forward the token and positions\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device)\n",
    "        pos_emb = self.transformer.wpe(pos) # (T, n_embd)\n",
    "        tok_emb = self.transformer.wte(idx) # (B, T, n_embd)\n",
    "        x = tok_emb + pos_emb\n",
    "        # forward the block\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        # forward the final layernorm and head\n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "        return logits, loss\n",
    "    \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type):\n",
    "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "        # create a from-scratch initialized minGPT model\n",
    "        config = GPTConfig(**config_args)\n",
    "        model = GPT(config)\n",
    "        sd = model.state_dict()\n",
    "        sd_keys = sd.keys()\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # init a huggingface/transformers model\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "        sd_hf = model_hf.state_dict()\n",
    "\n",
    "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
    "        sd_keys_hf = sd_hf.keys()\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
    "        # this means that we have to transpose these weights when we import them\n",
    "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sd_keys_hf:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sd_hf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def configure_optimizers(self, weight_decay, learning_rate, device_type):\n",
    "        # start with all of the candidate parameters (that require grad)\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "        optim_groups = [\n",
    "            {'params': decay_params, 'weight_decay': weight_decay},\n",
    "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        num_decay_params = sum(p.numel() for p in decay_params)\n",
    "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
    "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
    "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
    "        # Create AdamW optimizer and use the fused version if it is available\n",
    "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
    "        use_fused = fused_available and device_type == \"cuda\"\n",
    "        print(f\"using fused AdamW: {use_fused}\")\n",
    "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=(0.9, 0.95), eps=1e-8, fused=use_fused)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "class DataLoaderLite:\n",
    "    def __init__(self, B, T):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        with open(shake_data, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        enc = tiktoken.get_encoding('gpt2')\n",
    "        tokens = enc.encode(text)\n",
    "        self.tokens = torch.tensor(tokens)\n",
    "        print(f'loaded {len(self.tokens)} tokens')\n",
    "        print(f'1 epoch = {len(self.tokens) // (B*T)} batches')\n",
    "\n",
    "        self.current_position = 0\n",
    "\n",
    "    def next_batch(self):\n",
    "        B, T = self.B, self.T\n",
    "        buf = self.tokens[self.current_position : self.current_position+B*T+1]\n",
    "        x = (buf[:-1]).view(B, T) # inputs\n",
    "        y = (buf[1:]).view(B, T) # targets\n",
    "        # advance the position in the tensor\n",
    "        self.current_position += B * T \n",
    "        # if loading the next batch would be out of bounds, advance to next shard\n",
    "        if self.current_position + (B * T + 1) > len(self.tokens):\n",
    "            self.current_position = 0\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5dd887-eab0-46a0-9f62-0fe9a97b9468",
   "metadata": {},
   "source": [
    "## Create model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da37ac22-1031-4410-a046-bb87a577a23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total desired batch size: 131072\n",
      "=> calculated gradient accumulation steps: 32\n",
      "loaded 338025 tokens\n",
      "1 epoch = 82 batches\n"
     ]
    }
   ],
   "source": [
    "total_batch_size = 2**17 #524288 # 2**19, ~0.5M, in number of tokens\n",
    "B = 4 # micro batch size\n",
    "T = 1024 # sequence length\n",
    "assert total_batch_size % (B * T) == 0, \"make sure total_batch_size is divisible by B * T * ddp_world_size\"\n",
    "grad_accum_steps = total_batch_size // (B * T)\n",
    "print(f\"total desired batch size: {total_batch_size}\")\n",
    "print(f\"=> calculated gradient accumulation steps: {grad_accum_steps}\")\n",
    "\n",
    "train_loader = DataLoaderLite(B=B, T=T)\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "model = GPT(GPTConfig(vocab_size=50304)) # make divisible by power of 2\n",
    "model.to(device)\n",
    "model = torch.compile(model)\n",
    "lossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40477f04-4281-49a5-8f72-024d87a81fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 6e-4\n",
    "min_lr = max_lr * 0.1\n",
    "max_steps = 200\n",
    "warmup_steps = 0.2 * max_steps # 20% warmup\n",
    "weight_decay = 0.1\n",
    "def get_lr(it):\n",
    "    # 1/ linear warmup \n",
    "    if it < warmup_steps:\n",
    "        return max_lr * (it+1) / warmup_steps\n",
    "    # 2/ if iterations > lr_decay_iters, return min learning rate\n",
    "    if it > max_steps: \n",
    "        return min_lr\n",
    "\n",
    "    decay_ratio = (it - warmup_steps) / (max_steps - warmup_steps)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff starts at 1 and goes to 0\n",
    "    return min_lr + coeff * (max_lr - min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a87d6fd-1a76-4a86-b43d-3a13818d5801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 50, with 124,354,560 parameters\n",
      "num non-decayed parameter tensors: 98, with 121,344 parameters\n",
      "using fused AdamW: True\n"
     ]
    }
   ],
   "source": [
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=min_lr, betas=(0.9, 0.95), eps=1e-8)\n",
    "optimizer = model.configure_optimizers(weight_decay=weight_decay, learning_rate=max_lr, device_type=device)\n",
    "enc = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abfc6e0e-c232-4985-af9d-234c729e3b6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss of 10.967737197875977 with average time of 31975.6780ms | 1.5000e-05\n",
      "step 1: loss of 10.585558891296387 with average time of 29923.0061ms | 3.0000e-05\n",
      "step 2: loss of 9.96261978149414 with average time of 30190.4178ms | 4.5000e-05\n",
      "step 3: loss of 9.541036605834961 with average time of 30271.9138ms | 6.0000e-05\n",
      "step 4: loss of 9.232091903686523 with average time of 30375.6015ms | 7.5000e-05\n",
      "step 5: loss of 9.048246383666992 with average time of 30392.0698ms | 9.0000e-05\n",
      "step 6: loss of 8.935154914855957 with average time of 30391.7952ms | 1.0500e-04\n",
      "step 7: loss of 8.721705436706543 with average time of 30444.3164ms | 1.2000e-04\n",
      "step 8: loss of 8.678725242614746 with average time of 30400.0356ms | 1.3500e-04\n",
      "step 9: loss of 8.512798309326172 with average time of 30432.2765ms | 1.5000e-04\n",
      "sample 0: Hello, I'm a language model,\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ":\n",
      "\n",
      "\n",
      "\n",
      "sample 1: Hello, I'm a language model,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ":\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ":\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "step 10: loss of 8.303852081298828 with average time of 32989.5439ms | 1.6500e-04\n",
      "step 11: loss of 8.236567497253418 with average time of 30426.1098ms | 1.8000e-04\n",
      "step 12: loss of 8.03585433959961 with average time of 30427.5968ms | 1.9500e-04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m micro_step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(grad_accum_steps):\n\u001b[32m     36\u001b[39m     x, y = train_loader.next_batch()\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     x, y = \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, y.to(device)\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m#with torch.autocast(device_type=device, dtype=torch.bfloat16): # not supported on Tesla T4\u001b[39;00m\n\u001b[32m     40\u001b[39m     logits, loss = model(x, y)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for step in range(max_steps):\n",
    "    t0 = time.time()\n",
    "    last_step = (step == max_steps - 1)\n",
    "    \n",
    "    # once in a while generate from the model (except step 0, which is noise)\n",
    "    if ((step > 0 and step % 10 == 0) or last_step):\n",
    "        model.eval()\n",
    "        num_return_sequences = 2\n",
    "        max_length = 32\n",
    "        tokens = enc.encode('Hello, I\\'m a language model,')\n",
    "        tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "        tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)\n",
    "        xgen = tokens.to(device)\n",
    "        sample_rng = torch.Generator(device=device)\n",
    "        sample_rng.manual_seed(42)\n",
    "        while xgen.size(1) < max_length:\n",
    "            # forward the model to get the logits\n",
    "            with torch.no_grad():\n",
    "                logits, loss = model(xgen)\n",
    "                logits = logits[:, -1, :]\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "                topk_probs, topk_indices = torch.topk(probs, 50, dim=-1) # limit tensor size by sampling\n",
    "                ix = torch.multinomial(topk_probs, 1, generator=sample_rng) # (B, 1)\n",
    "                xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "                xgen = torch.cat((xgen, xcol), dim=1)\n",
    "        # print the generated text\n",
    "        for i in range(num_return_sequences):\n",
    "            tokens = xgen[i, :max_length].tolist()\n",
    "            decoded = enc.decode(tokens)\n",
    "            print(f\"sample {i}: {decoded}\")\n",
    "            \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss_accum = 0.0\n",
    "    for micro_step in range(grad_accum_steps):\n",
    "        x, y = train_loader.next_batch()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        #with torch.autocast(device_type=device, dtype=torch.bfloat16): # not supported on Tesla T4\n",
    "        logits, loss = model(x, y)\n",
    "        loss = loss / grad_accum_steps\n",
    "        loss_accum += loss.detach()\n",
    "        loss.backward()\n",
    "        #print(f'microstep {micro_step}/{grad_accum_steps} | loss {loss_accum}')\n",
    "    \n",
    "    norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # clips gradient to avoid very high gradients that shock model \n",
    "    # set LR for this step\n",
    "    lr = get_lr(step)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    optimizer.step()\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    dt = (t1-t0)*1000 # time diff in MS \n",
    "    print(f'step {step}: loss of {loss_accum.item()} with average time of {dt:.4f}ms | {lr:.4e}')\n",
    "    lossi.append(loss_accum.item())\n",
    "\n",
    "    if step > 0 and (step % 50 == 0 or last_step):\n",
    "        cp_dir = Path('/home/ubuntu/model')\n",
    "        cp_path = cp_dir / f'model_{step:05d}.pt'\n",
    "        checkpoint = {\n",
    "            'model': model.state_dict(),\n",
    "            'config': model.config,\n",
    "            'step': step, \n",
    "            'val_loss': loss_accum.item()\n",
    "        }\n",
    "        torch.save(checkpoint, cp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92e2f890-77b4-4248-b101-8ed73a000122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7bcb345fb250>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfee0b4c-e63a-4804-9770-b802829bc224",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 12\n",
    "cp_dir = Path('/home/ubuntu/model')\n",
    "cp_path = cp_dir / f'model_{step:05d}.pt'\n",
    "checkpoint = {\n",
    "    'model': model.state_dict(),\n",
    "    'config': model.config,\n",
    "    'step': step, \n",
    "    'val_loss': loss_accum.item()\n",
    "}\n",
    "torch.save(checkpoint, cp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "365c5bce-5115-4c6f-8afb-f45abef3d852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 31 01:33:56 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   49C    P0             35W /   70W |    7525MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            3574      C   ...3/envs/general/bin/python3.13       7522MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b332c42c-da62-4a86-9706-9331e0cf30c6",
   "metadata": {},
   "source": [
    "### Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7cfbeb1-ebb7-42df-baed-724eba8dbdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0: Hello, I'm a language model,\n",
      "\n",
      "\n",
      "\n",
      "And\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ":\n",
      "\n",
      "\n",
      "\n",
      "sample 1: Hello, I'm a language model,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ", her\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "num_return_sequences = 2\n",
    "max_length = 32\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode('Hello, I\\'m a language model,')\n",
    "tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)\n",
    "xgen = tokens.to(device)\n",
    "sample_rng = torch.Generator(device=device)\n",
    "sample_rng.manual_seed(42)\n",
    "while xgen.size(1) < max_length:\n",
    "    # forward the model to get the logits\n",
    "    with torch.no_grad():\n",
    "        logits, loss = model(xgen)\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1) # limit tensor size by sampling\n",
    "        ix = torch.multinomial(topk_probs, 1, generator=sample_rng) # (B, 1)\n",
    "        xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "        xgen = torch.cat((xgen, xcol), dim=1)\n",
    "# print the generated text\n",
    "for i in range(num_return_sequences):\n",
    "    tokens = xgen[i, :max_length].tolist()\n",
    "    decoded = enc.decode(tokens)\n",
    "    print(f\"sample {i}: {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b90ee8-6a38-47fa-8937-49b7696b7640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
